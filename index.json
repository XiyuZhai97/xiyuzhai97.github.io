[{"authors":["admin"],"categories":null,"content":"After graduate with a master's degree in EECS from UC Berkeley, Xiyu joined Amazon Prime Air working on some interesting projects.\nHis research interests include robotics, multi-agent control theory and graphics. In college, he worked with Prof. Alex Bayen on an open sourced robotics platform for deep reinforcement learning and the project Flow. He also actively with Allen Yang on an AR semantic scene generation project.\n","date":1596345229,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1596345229,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://www.zhaixiyu.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"After graduate with a master's degree in EECS from UC Berkeley, Xiyu joined Amazon Prime Air working on some interesting projects.\nHis research interests include robotics, multi-agent control theory and graphics. In college, he worked with Prof. Alex Bayen on an open sourced robotics platform for deep reinforcement learning and the project Flow. He also actively with Allen Yang on an AR semantic scene generation project.","tags":null,"title":"Xiyu Zhai","type":"authors"},{"authors":[],"categories":[],"content":"\r\r\r\r\r\r ","date":1596778728,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596778728,"objectID":"38f40d313c5e667926a64ecd3a026e9d","permalink":"https://www.zhaixiyu.com/post/ridiculoususagov/","publishdate":"2020-08-06T22:38:48-07:00","relpermalink":"/post/ridiculoususagov/","section":"post","summary":"   ","tags":[],"title":"Ridiculous USA Government","type":"post"},{"authors":["Xiyu Zhai"],"categories":["reference"],"content":"Ctrl+a Ctrl+a : Go to head of the command line\nw : Move cursor forward one word at a time\nb : Move cursor backward one word at a time\nSession   Ctrl+a :new -s mysession\n  Ctrl+a d : Detach from session (exit tmux)\n  Ctrl+a s : Show all sessions\n  Ctrl+a $ : Rename session\n  Ctrl+a :kill-session -t XXX\n  Ctrl+a ( : Move to previous session\n  Ctrl+a ) : Move to next session\n  Ctrl+a w : Show all sessions and windows\n  Window (quick switch)   Ctrl+a c : Create window\n  Ctrl+a , : Rename current windows\n  Ctrl+a \u0026amp; : Close current window\n  Ctrl+a n : Next window\n  Ctrl+a 0…9 : Show all sessions\n  Ctrl+a $ : Switch/select window by number\n  Ctrl+a :swap-window -s 2 -t 1 Reorder window, swap window number 2(src) and 1(dst)\n  Ctrl+a :swap-window -t -1 Move current window to the left by one position\n  Panes   Ctrl+a % : Split pane vertically\n  Ctrl+a \u0026ldquo; : Split pane horizontally\n  Ctrl+a [arrow key] : Switch to pane to the direction\n  Ctrl+a ; : Toggle last active pane\n  Ctrl+a o : Switch to next pane\n  Ctrl+a { : Move the current pane left\n  Ctrl+a } : Move the current pane right\n  Ctrl+a x : Close current pane\n  Ctrl+a ! : Convert pane into a window\n  Ctrl+a z : Toggle pane zoom\n  Ctrl+a+[arrow key] : Resize current pane size\n  Ctrl+a q : Show pane numbers\n  Ctrl+a q 0…9 : Switch/select pane by number\n  .tmux.conf # Set the default TERM\rset -g default-terminal screen\r# Update the TERM variable of terminal emulator when creating a new session or attaching a existing session\r# (Note: the space is needed so it doesn't merge with previous variables)\u0026quot;\rset-option -ga update-environment \u0026quot; TERM\u0026quot;\r# Determine if we should enable 256-colour support\rif \u0026quot;[[ ${TERM} =~ 256color || ${TERM} == fbterm ]]\u0026quot; 'set -g default-terminal screen-256color'\r# Ring the bell if any background window rang a bell\rset -g bell-action any\r# Update custom sent env vars\r# https://babushk.in/posts/renew-environment-tmux.html\r# https://stackoverflow.com/a/9833996\rset-option -ga update-environment \u0026quot; LC_USER_KEYNAME \\\rLC_USER_NAME \\\rLC_USER_EMAIL \\\rLC_USER \\\rLC_USER_WORKSPACE\u0026quot;\r# color scheme (styled as vim-powerline)\rset -g status-left-length 52\rset -g status-right-length 451\rset -g status-fg white\rset -g status-bg colour234\rset -g pane-border-style fg=colour245\rset -g pane-active-border-style fg=colour39\rset -g message-style fg=colour16,bg=colour221,bold\rset -g status-left '#[fg=colour235,bg=colour252,bold]#S #[fg=colour252,bg=colour238,nobold]#[fg=colour245,bg=colour238,bold] #(whoami)#[fg=colour238,bg=colour234,nobold]'\rset -g window-status-format \u0026quot;#[fg=colour235,bg=colour252,bold] #I #W \u0026quot;\rset -g window-status-current-format \u0026quot;#[fg=colour234,bg=colour39]#[fg=colour235,bg=colour39,noreverse,bold] #I: #W #[fg=colour39,bg=colour234,nobold]\u0026quot;\r# Bigger history\rset -g history-limit 10000\r# Set default shell to $SHELL\rset-option -g default-shell $SHELL\r# Setting the prefix from C-b to C-a\rset -g prefix C-a\r# Free the original Ctrl-b prefix keybinding\runbind C-b\r#setting the delay between prefix and command\rset -sg escape-time 0\r# Ensure that we can send Ctrl-A to other apps\rbind C-a send-prefix\r# Set the base index for windows to 1 instead of 0\rset -g base-index 1\r# Set the base index for panes to 1 instead of 0\rsetw -g pane-base-index 1\r# Reload the file with Prefix r\rbind r source-file ~/.tmux.conf \\; display \u0026quot;Reloaded!\u0026quot;\r# splitting panes\rbind | split-window -h\rbind - split-window -v\r# Pane resizing\rbind -r H resize-pane -L 5\rbind -r J resize-pane -D 5\rbind -r K resize-pane -U 5\rbind -r L resize-pane -R 5\r# Create new window next to the current one\rbind n new-window -a\r# mouse support - set to on if you want to use the mouse\rset-option -g mouse on\r# Set the default terminal mode to 256color mode\rset -g default-terminal \u0026quot;screen-256color\u0026quot;\r# enable activity alerts\rsetw -g monitor-activity on\rset -g visual-activity on\r# Center the window list\rset -g status-justify centre\r# enable vi keys.\rsetw -g mode-keys vi\r# Vim clipboard bindings\runbind [\rbind Escape copy-mode\runbind p\rbind p paste-buffer\rbind-key -T copy-mode-vi v send-keys -X begin-selection\rbind-key -T copy-mode-vi y send-keys -X copy-selection\r# Tmux clear history\rbind C-k send-keys -R \\; clear-history \\; send-keys C-l\rbind C-l send-keys 'C-l'\rbind-key Y command-prompt -p 'save history to filename:' -I '~/tmux.history' 'capture-pane -S - ; save-buffer %1 ; delete-buffer'\rbind -n S-Left previous-window\rbind -n S-Right next-window\rset -g @plugin 'tmux-plugins/tpm'\rset -g @plugin 'tmux-plugins/tmux-resurrect'\rset -g @plugin 'christoomey/vim-tmux-navigator'\rset-environment -g TMUX_PLUGIN_MANAGER_PATH '~/.tmux/plugins/'\rrun -b '~/.tmux/plugins/tpm/tpm'\r","date":1596345229,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596345229,"objectID":"239f1b8ce76e3c2a90389c475ba53418","permalink":"https://www.zhaixiyu.com/post/cheatsheet-tmux/","publishdate":"2020-08-01T22:13:49-07:00","relpermalink":"/post/cheatsheet-tmux/","section":"post","summary":"Use tmux for efficiency","tags":["tools","cheatsheet"],"title":"Tmux Cheatsheet","type":"post"},{"authors":null,"categories":null,"content":"Developers of AR apps often place virtual objects arbitrarily in front of the user with no consideration of their surroundings. However, resulting illogical placements make the AR feel less realistic. We seek a more nuanced method of virtual object placement that takes objects in the user’s environment into account.\nWe developed an interface to generate heatmaps indicating likely placements for new objects of different types (eg. bed, chair, table, etc.). This interface can be run from Unity or as an AR application on IOS.\n","date":1594944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594944000,"objectID":"3b2cfdcba947f588d0b3608a2c30edb3","permalink":"https://www.zhaixiyu.com/project/ar-semantic-scene-generation/","publishdate":"2020-07-17T00:00:00Z","relpermalink":"/project/ar-semantic-scene-generation/","section":"project","summary":"Seek a more nuanced method of virtual object placement based on users' environments.","tags":["Graphics","Machine Learning","ARVR"],"title":"AR Semantic Scene Generation","type":"project"},{"authors":null,"categories":null,"content":"  Design and build a reliable open-source physical robotic platform for multi-agent learning and control research at an acceptable cost.\n  Designed and built (with 3D printer) two kinds of mini-robots based on Arduino-like MCU, and NVIDIA Jetson.\n  Implemented a very robust and precise localization and speed detection algorithm to perceive the environment information for the traffic planning. with a central camera, infrared cameras, and onboard tracking tags.\n  Built the communication network among the controlling server, the central camera, and 20 mini-robots via ROS\n  Transferred learning from simulations to this controlled robotic platform to validate the effectiveness of the Deep Reinforcement Learning based control design of Flow framework\n  ","date":1589500800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589500800,"objectID":"ab86e01d74314afc419a6f13b561c8e2","permalink":"https://www.zhaixiyu.com/project/robotics-platform-for-traffic-simulation/","publishdate":"2020-05-15T00:00:00Z","relpermalink":"/project/robotics-platform-for-traffic-simulation/","section":"project","summary":"Pixel Learning with Deep-RL for Mixed Autonomy Traffic","tags":["Robotics","Control","Machine Learning","Reinforcement Learning"],"title":"Robotics Platform for Traffic Simulation","type":"project"},{"authors":["Xiyu Zhai"],"categories":["thoughts"],"content":"Application: Traffic flow simulation and prediction The problem to solve As autonomous vehicles become more popular and more sensors are deployed on the road, it is now possible to build a better transportation simulation system containing historic data for traffic flow prediction. And a city-scale transportation network simulation will require a combination of statistical skills and computing techniques that can take advantage of abundant hardware. \\\nThe major way to predict the traffic flow situation is machine learning. However, complex neural networks model often takes a long time to train. Therefore it will be extremely useful to scale the training process, leading to drastically decrease in training time and increase in accuracy\\cite{zhao2019parallel}. \\\nBackpropagation neural network (BPNN) is one of the most widely used model due to its excellent function approximation ability. A typical BPNN usually contains three kinds of layers including input layer, hidden layer, and output layer. Input layer is the entrance of the algorithm. It inputs one instance of the data into the network. The dimension of the instance determines the number of inputs in the input layer. Hidden layer contains one or several layers. It outputs intermediate data to the output layer that generates the final output of the neural network. The number of outputs is determined by the encoding of the classified results. In BPNN each layer consists of a number of neurons. The linear functions or nonlinear functions in each neuron are frequently controlled by two kinds of parameters, weight and bias. \\\nIn the training phase, BPNN employs feed forward to generate output. And then it calculates the error between the output and the target output. Afterwards, BPNN employs backpropagation to tune weights and biases in neurons based on the calculated error. In the classifying phase, BPNN only executes feed forward to achieve the ultimate classified result. Although it is difficult to determine an optimal number of the hidden layers and neurons for one classification task, it is proved that a three-layer BPNN is enough to fit the mathematical equations which approximate the mapping relationships between the inputs and the outputs. While due to a large number of mathematical calculations existing in the algorithm, low efficiency of BPNN leads to performance deterioration in both training phase and classification phase when the data size is large. \\\nObjective Build a efficient parallel computing framework for traffic flow simulation on large-scale networks. For large scale city, we can divide the transportation into several modules based on its location and function. The simulation of all targets(cars, pedestrians, buses, bicycles) inside one module will be processed individually. And \u0026ldquo;various types of simulation events are mapped to independent logical processes that can concurrently execute their procedures while maintaining good load balance\u0026rdquo;\\cite{qu2017large}. The connection between each module will be managed by time sequence and location information. \\\nBuild a efficient parallel computing method to accelerate training the deep neural network that predicts the future traffic flow for real-time control. We may build a multi-process training framework for Pytorch or Tensorflow Neural Networks.\n","date":1580540657,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580540657,"objectID":"eb3ce57834dae4968aa12b95b4b8f812","permalink":"https://www.zhaixiyu.com/post/parallelcomputpre/","publishdate":"2020-01-31T23:04:17-08:00","relpermalink":"/post/parallelcomputpre/","section":"post","summary":"Traffic flow simulation and prediction","tags":["parallel","courses"],"title":"Application of Parallel Computing in Traffic Flow Control","type":"post"},{"authors":null,"categories":null,"content":"  Built mathematical models and performance evaluation indicators for power converters.\n  Implemented several control strategies with zero steady-state error that output 100-order harmonics in C++ based on multi-time synchronous rotating frame and PR control.\n  Developed a power converter controlling a Reinforcement Learning framework that robust enough to generate over 200-order harmonics.\n  ","date":1577295240,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577295240,"objectID":"08aa2cfa8ac0347a2963ccb26a5f7e6e","permalink":"https://www.zhaixiyu.com/project/control-method-for-power-converter/","publishdate":"2019-12-25T17:34:00Z","relpermalink":"/project/control-method-for-power-converter/","section":"project","summary":"Deadbeat Control Strategy of Electronic Converter","tags":["Control","Machine Learning","Reinforcement Learning"],"title":"High Frequency Power Transformer Control","type":"project"},{"authors":["Xiyu Zhai"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://www.zhaixiyu.com/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Welcome to Slides academia\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34;\rif porridge == \u0026#34;blueberry\u0026#34;:\rprint(\u0026#34;Eating...\u0026#34;)\r Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\rPress Space to play!\nOne Two Three  A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\rPress the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view \r  Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}}\r{{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}\r Custom CSS Example Let's make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://www.zhaixiyu.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using academia's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"  Designed and built a robotic hand with 16 degrees of freedom using 3d printer.\n  Implemented the real-time control of the robotic hand to imitating gestures using Node.js with a Leap Motion\n  Built a deep learning model with TensorFlow that can recognize the key points of hands from images taken by a regular camera within 25 milliseconds (improve from 110ms).\n  ","date":1546873800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546873800,"objectID":"327ff546e93af9896b1e3b42eba60b41","permalink":"https://www.zhaixiyu.com/project/robot-hand-design/","publishdate":"2019-01-07T15:10:00Z","relpermalink":"/project/robot-hand-design/","section":"project","summary":"Robotic Hand Design with Computer Vision.","tags":["Robotics","Control","Computer Vision"],"title":"Robotics Hand Design","type":"project"},{"authors":["Xiyu Zhai","Robert Ford"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://www.zhaixiyu.com/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Xiyu Zhai","Robert Ford"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://www.zhaixiyu.com/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]